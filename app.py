{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7003a37-6f36-4de3-a617-2e0d21c4a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app.py\n",
    "\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# --- 1. Constants and Initial Setup ---\n",
    "MODEL_PATH = 'naive_bayes_intent_model.joblib'\n",
    "VECTORIZER_PATH = 'tfidf_vectorizer.joblib'\n",
    "DATASET_PATH = 'dataset.csv' # æ–°å¢ï¼šæ•°æ®é›†è·¯å¾„\n",
    "\n",
    "# --- 2. Load Model, Vectorizer, and Data ---\n",
    "\n",
    "@st.cache_resource # ç¼“å­˜èµ„æºä»¥é¿å…åœ¨æ¯æ¬¡é‡è¿è¡Œæ—¶é‡å¤åŠ è½½\n",
    "def load_resources():\n",
    "    \"\"\"åŠ è½½ä¿å­˜çš„æ¨¡å‹ã€å‘é‡åŒ–å™¨å’Œæ•°æ®é›†ã€‚\"\"\"\n",
    "    model, vectorizer, df = None, None, None\n",
    "    try:\n",
    "        model = load(MODEL_PATH)\n",
    "        vectorizer = load(VECTORIZER_PATH)\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: Could not find model or vectorizer files. Please ensure '{MODEL_PATH}' and '{VECTORIZER_PATH}' are present.\")\n",
    "        st.stop()\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred while loading resources: {e}\")\n",
    "        st.stop()\n",
    "        \n",
    "    try:\n",
    "        df = pd.read_csv(DATASET_PATH)\n",
    "    except FileNotFoundError:\n",
    "        st.warning(f\"Warning: Could not find dataset file '{DATASET_PATH}'. Quick query buttons will be disabled.\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred while loading the dataset: {e}\")\n",
    "        \n",
    "    return model, vectorizer, df\n",
    "\n",
    "nb_model, vectorizer, df_data = load_resources()\n",
    "\n",
    "# --- 3. Predefined Responses ---\n",
    "\n",
    "responses = {\n",
    "    \"ask_room_price\": \"Our rooms start from RM180 per night.\",\n",
    "    \"ask_availability\": \"We currently have several rooms available.\",\n",
    "    \"ask_facilities\": \"We offer free Wi-Fi, breakfast, pool, gym and parking.\",\n",
    "    \"ask_location\": \"We are located in Kuala Lumpur City Centre (KLCC).\",\n",
    "    \"ask_checkin_time\" : \"Check-in time is from 2:00 PM.\",\n",
    "    \"ask_checkout_time\" : \"Check-out time is at 12:00 PM.\",\n",
    "    \"ask_booking\" : \"You can book directly through our website or at the front desk.\",\n",
    "    \"ask_cancellation\" : \"Cancellations are free up to 24 hours before arrival.\",\n",
    "    \"greeting\" : \"Hello! How may I assist you today?\",\n",
    "    \"goodbye\" : \"Goodbye! Have a great day!\"\n",
    "}\n",
    "\n",
    "# --- 4. Chatbot Logic Function (Same as before) ---\n",
    "\n",
    "def chatbot_reply_nb(user_input, model, vectorizer, responses):\n",
    "    \"\"\"æ ¹æ®ç”¨æˆ·è¾“å…¥é¢„æµ‹æ„å›¾å¹¶è¿”å›ç›¸åº”å›å¤ã€‚\"\"\"\n",
    "    if not user_input.strip():\n",
    "        return \"Please enter a question to start the conversation.\", \"Empty Input\", 0.0\n",
    "\n",
    "    processed_input = user_input.lower()\n",
    "    vector = vectorizer.transform([processed_input])\n",
    "    probabilities = model.predict_proba(vector)[0]\n",
    "    intent_index = np.argmax(probabilities)\n",
    "    confidence = probabilities[intent_index]\n",
    "    intent = model.classes_[intent_index]\n",
    "    \n",
    "    CONFIDENCE_THRESHOLD = 0.3\n",
    "    \n",
    "    if confidence < CONFIDENCE_THRESHOLD:\n",
    "        reply = f\"Sorry, I'm not sure I understand. My predicted intent ('{intent}') had a low confidence score ({confidence:.2f}). Could you please rephrase?\"\n",
    "        predicted_intent = \"Fallback (Low Confidence)\"\n",
    "    else:\n",
    "        reply = responses.get(intent, f\"Sorry, I predicted the intent **'{intent}'** (Confidence: {confidence:.2f}), but I don't have a specific response for that yet. Please rephrase your question.\")\n",
    "        predicted_intent = intent\n",
    "\n",
    "    return reply, predicted_intent, confidence\n",
    "\n",
    "# --- 5. Core Chat Function (Handles the interaction flow) ---\n",
    "\n",
    "def handle_chat_interaction(prompt):\n",
    "    \"\"\"å¤„ç†ç”¨æˆ·è¾“å…¥ã€æ›´æ–°èŠå¤©å†å²å¹¶ç”Ÿæˆå›å¤ã€‚\"\"\"\n",
    "    # 1. å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    # 2. è·å–èŠå¤©æœºå™¨äººå›å¤\n",
    "    reply, predicted_intent, confidence = chatbot_reply_nb(prompt, nb_model, vectorizer, responses)\n",
    "    \n",
    "    # 3. å­˜å‚¨æœºå™¨äººæ¶ˆæ¯åˆ°å†å²\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": reply, \"intent\": predicted_intent, \"confidence\": confidence})\n",
    "    \n",
    "    # 4. å¼ºåˆ¶é‡æ–°è¿è¡Œä»¥æ˜¾ç¤ºæ–°çš„å†å²æ¶ˆæ¯\n",
    "    # Streamlit é€šå¸¸ä¼šè‡ªå·±åˆ·æ–°ï¼Œä½†è¿™ä¸ª pattern åœ¨æŸäº›æƒ…å†µä¸‹æ›´å¯é \n",
    "    st.rerun()\n",
    "\n",
    "\n",
    "# --- 6. Streamlit UI Setup ---\n",
    "\n",
    "st.set_page_config(page_title=\"Intent-Based Chatbot Demo\", layout=\"centered\")\n",
    "\n",
    "st.title(\"ğŸ›ï¸ Intent-Based Chatbot Demo\")\n",
    "st.markdown(\"Powered by **Multinomial Naive Bayes** and **TF-IDF**.\")\n",
    "\n",
    "# åˆå§‹åŒ–å¯¹è¯å†å²ï¼ˆä½¿ç”¨ session stateï¼‰\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "    # åˆå§‹æ¬¢è¿è¯­\n",
    "    initial_response = responses[\"greeting\"]\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": initial_response, \"intent\": \"greeting\", \"confidence\": 1.0})\n",
    "\n",
    "# --- Quick Query Buttons ---\n",
    "if df_data is not None and not df_data.empty:\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"ğŸš€ Quick Queries from Dataset\")\n",
    "    \n",
    "    # ä»æ•°æ®é›†ä¸­éšæœºæŠ½å–æœ€å¤š 5 ä¸ªæ ·æœ¬\n",
    "    quick_queries = df_data['text'].sample(min(5, len(df_data)), random_state=42).tolist()\n",
    "    \n",
    "    # ä½¿ç”¨ st.columns æˆ– st.button æ¥åˆ›å»ºæŒ‰é’®å¸ƒå±€\n",
    "    cols = st.columns(len(quick_queries))\n",
    "    for i, query in enumerate(quick_queries):\n",
    "        if cols[i].button(query):\n",
    "            # å½“æŒ‰é’®è¢«ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨å¤„ç†å‡½æ•°\n",
    "            handle_chat_interaction(query)\n",
    "\n",
    "# --- Display Chat History ---\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.markdown(message[\"content\"])\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            if \"intent\" in message and message[\"intent\"] != \"greeting\":\n",
    "                st.caption(f\"**Predicted Intent:** {message['intent']} | **Confidence:** {message['confidence']:.2f}\")\n",
    "\n",
    "# --- User Input Text Box ---\n",
    "if prompt := st.chat_input(\"Ask a question about the hotel:\"):\n",
    "    handle_chat_interaction(prompt)\n",
    "\n",
    "st.markdown(\"---\")\n",
    "st.subheader(\"ğŸ’¡ Supported Intents\")\n",
    "st.code(\", \".join(responses.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
